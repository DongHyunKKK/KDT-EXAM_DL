{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    # 모델 구성 요소 생성 및 구조 설정\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()  # super()로 써도 된다. 즉 괄호 안에 Net, self 생략가능\n",
    "\n",
    "        self.layer1 = nn.Linear(8, 4)\n",
    "        self.layer2 = nn.Linear(4, 2)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.layer3 = nn.Linear(2, 1)\n",
    "\n",
    "    # 순방향 학습 진행 함수\n",
    "    def forward(self, x):\n",
    "        return self.layer3(self.drop(self.layer2(self.layer1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.1691,  0.2798, -0.0950, -0.1396, -0.1234, -0.3406,  0.0381, -0.2404],\n",
       "         [ 0.0901,  0.3532, -0.0166,  0.1572,  0.2618, -0.1659,  0.0367, -0.1298],\n",
       "         [-0.3021, -0.3519,  0.2821,  0.3363, -0.2424, -0.2845,  0.3389, -0.2313],\n",
       "         [-0.2973,  0.2145,  0.2701, -0.2435,  0.2934,  0.2751,  0.2423,  0.1479]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0989,  0.2592, -0.0798, -0.2185], requires_grad=True))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스 속성 확인\n",
    "# 모델의 특정 층 추출\n",
    "model.layer1.weight, model.layer1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1691,  0.2798, -0.0950, -0.1396, -0.1234, -0.3406,  0.0381, -0.2404],\n",
      "        [ 0.0901,  0.3532, -0.0166,  0.1572,  0.2618, -0.1659,  0.0367, -0.1298],\n",
      "        [-0.3021, -0.3519,  0.2821,  0.3363, -0.2424, -0.2845,  0.3389, -0.2313],\n",
      "        [-0.2973,  0.2145,  0.2701, -0.2435,  0.2934,  0.2751,  0.2423,  0.1479]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.0989,  0.2592, -0.0798, -0.2185], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.3600, -0.0955,  0.2970, -0.0391],\n",
      "        [-0.3290, -0.0510,  0.3208, -0.3411]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0.1889, 0.0932], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.3480, 0.2892]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.4298], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param, end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('layer1.weight', Parameter containing:\n",
      "tensor([[-0.1691,  0.2798, -0.0950, -0.1396, -0.1234, -0.3406,  0.0381, -0.2404],\n",
      "        [ 0.0901,  0.3532, -0.0166,  0.1572,  0.2618, -0.1659,  0.0367, -0.1298],\n",
      "        [-0.3021, -0.3519,  0.2821,  0.3363, -0.2424, -0.2845,  0.3389, -0.2313],\n",
      "        [-0.2973,  0.2145,  0.2701, -0.2435,  0.2934,  0.2751,  0.2423,  0.1479]],\n",
      "       requires_grad=True))\n",
      "\n",
      "('layer1.bias', Parameter containing:\n",
      "tensor([-0.0989,  0.2592, -0.0798, -0.2185], requires_grad=True))\n",
      "\n",
      "('layer2.weight', Parameter containing:\n",
      "tensor([[-0.3600, -0.0955,  0.2970, -0.0391],\n",
      "        [-0.3290, -0.0510,  0.3208, -0.3411]], requires_grad=True))\n",
      "\n",
      "('layer2.bias', Parameter containing:\n",
      "tensor([0.1889, 0.0932], requires_grad=True))\n",
      "\n",
      "('layer3.weight', Parameter containing:\n",
      "tensor([[0.3480, 0.2892]], requires_grad=True))\n",
      "\n",
      "('layer3.bias', Parameter containing:\n",
      "tensor([-0.4298], requires_grad=True))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델의 각 층별 w, b 텐서 정보 확인\n",
    "for param in model.named_parameters():\n",
    "    print(param, end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=8, out_features=4, bias=True)\n",
      "\n",
      "Linear(in_features=4, out_features=2, bias=True)\n",
      "\n",
      "Dropout(p=0.5, inplace=False)\n",
      "\n",
      "Linear(in_features=2, out_features=1, bias=True)\n",
      "\n",
      "('layer1', Linear(in_features=8, out_features=4, bias=True))\n",
      "\n",
      "('layer2', Linear(in_features=4, out_features=2, bias=True))\n",
      "\n",
      "('drop', Dropout(p=0.5, inplace=False))\n",
      "\n",
      "('layer3', Linear(in_features=2, out_features=1, bias=True))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델을 구성하는 모든 Layer 가져오기\n",
    "for child in model.children():\n",
    "    print(child, end = '\\n\\n')\n",
    "\n",
    "# 이름까지 같이 출력\n",
    "for child in model.named_children():\n",
    "    print(child, end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer의 가중치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5895, -0.0710, -0.7026,  0.2660, -0.0344, -0.1886, -0.1574, -0.5267],\n",
       "        [-0.7016, -0.4249,  0.1510,  0.5589, -0.2270,  0.2366,  0.5266, -0.5480],\n",
       "        [ 0.0083,  0.1225, -0.3105,  0.2836,  0.5705, -0.5360, -0.3386,  0.6806],\n",
       "        [-0.0921, -0.6355,  0.6413,  0.1715,  0.5771, -0.3374, -0.3321, -0.4997]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세비어 알고리즘의 가중치 초기화\n",
    "nn.init.xavier_uniform_(model.layer1.weight)  # inplace = True가 디폴트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6015, -0.2776,  0.1005,  0.2169],\n",
       "        [ 0.0891, -0.6482, -0.9764, -0.1793]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 헤 알고리즘의 가중치 초기화\n",
    "nn.init.kaiming_normal_(model.layer2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model, '../model/my_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Linear(in_features=8, out_features=4, bias=True)\n",
       "  (layer2): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (layer3): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델 불러오기\n",
    "mymodel = torch.load('../model/my_model.pt')\n",
    "mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (layer2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (layer3): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "├─Linear: 1-1                            36\n",
       "├─Linear: 1-2                            10\n",
       "├─Dropout: 1-3                           --\n",
       "├─Linear: 1-4                            3\n",
       "=================================================================\n",
       "Total params: 49\n",
       "Trainable params: 49\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = Net()\n",
    "\n",
    "print(model)\n",
    "\n",
    "summary(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
